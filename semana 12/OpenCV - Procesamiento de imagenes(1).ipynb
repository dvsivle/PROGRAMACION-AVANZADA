{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV - Procesamiento de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulación de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 600, 3)\n",
      "(450, 600)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"sample6.jpg\", cv2.IMREAD_COLOR)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(img.shape)\n",
    "print(gray.shape)\n",
    "\n",
    "cv2.imshow(\"Imagen BGR\", img)\n",
    "cv2.imshow(\"Imagen Gray\", gray)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Image (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"sample6.jpg\", cv2.IMREAD_COLOR)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_roi = img[100:350,250:400,:] \n",
    "gray_roi = gray[100:350,250:400]\n",
    "\n",
    "cv2.imshow(\"Imagen BGR\", img_roi)\n",
    "cv2.imshow(\"Imagen Gray\", gray_roi)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dibujo de figuras con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"sample2.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.line(img, (50, 100), (50, 400), (0, 255, 0), 2)   # imagen, punto de inicio, punto fianl, color, grosor\n",
    "                                                                # (columna de pixel,fila de pixel)\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"sample6.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.rectangle(img, (250, 120), (400, 300), (0, 255, 0), 2)  \n",
    "\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"sample3.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.circle(img, (250, 400), 100, (0, 255, 0), 2)   # imagen, centro, radio, color, grosor\n",
    "\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Blending (addWeighted)\n",
    "Se puede realizar una suma de imagenes, asignando un peso porcentual a cada imagen. Esto requiere que ambas imagenes tengan las mismas dimensiones y los mismos canales de colores (es decir, la misma forma). Los parametros de la formula (alpha, beta y gama) estan definidos para:\n",
    "\n",
    "$$dst = \\alpha * img1 + \\beta * imag + \\gamma $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 667, 3)\n",
      "(500, 667, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread(\"sample2.jpg\", cv2.IMREAD_COLOR)\n",
    "print(img1.shape)\n",
    "\n",
    "img2 = cv2.imread(\"sample1.jpg\", cv2.IMREAD_COLOR)\n",
    "img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "print(img2.shape)\n",
    "\n",
    "img_photo = cv2.addWeighted(img1, 0.7, img2, 0.3, 0) \n",
    "cv2.imshow(\"Imagen\", img_photo)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "img = cv2.imread(\"monalisa.jpg\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    img_blended = cv2.addWeighted(img, 0.7, frame, 0.3, 0)\n",
    "    cv2.imshow('MonaLisa', img_blended)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones lógicas (bitwise)\n",
    "Se puede realizar operaciones lógicas con los arreglos de imagenes a novel de OpenCV, asi como operaciones aritmeticas. Con estas operaciones se pueden hacer tratamientos especiales a las imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread(\"sample4.jpg\", cv2.IMREAD_COLOR)\n",
    "img2 = cv2.imread(\"upc_logo.jpg\", cv2.IMREAD_COLOR)\n",
    "img2 = cv2.resize(img2, (80, 80))\n",
    "roi = img1[-80:, -80:]\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "\n",
    "# Se crea una mascara con la imagen del logo con un control de umbral (threshold)\n",
    "# y se invierte la imagen con una operacion logica (bitwise_not)\n",
    "img_gray= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "\n",
    "# Hay que oscurecer los pixels que seran reemplazados por el logo (ROI)\n",
    "img_bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "cv2.imshow(\"img1_bg\", img_bg)\n",
    "\n",
    "# Hay que tomar solo los puntos que conforman en logo (mascara)\n",
    "img_fg = cv2.bitwise_and(img2, img2, mask=mask_inv)\n",
    "cv2.imshow(\"img2_fg\", img_fg)\n",
    "\n",
    "# Hay que sumar ambas imagenes en el ROI\n",
    "dst = cv2.add(img_bg, img_fg)\n",
    "img1[-80:, -80:] = dst\n",
    "cv2.imshow(\"Imagen con logo\", img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def put_logo(img, logo, roi):\n",
    "    gray= cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    fondo = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "    frente = cv2.bitwise_and(logo, logo, mask=mask_inv)\n",
    "\n",
    "    dst = cv2.add(fondo, frente)\n",
    "    img[-100:-20, -80:] = dst\n",
    "    \n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    logo = cv2.imread(\"upc_logo.jpg\", cv2.IMREAD_COLOR)\n",
    "    logo = cv2.resize(logo, (80, 80))\n",
    "    roi = img[-100:-20, -80:]\n",
    "    \n",
    "    img_with_logo = put_logo(img, logo, roi)\n",
    "    \n",
    "    cv2.imshow(\"Video Logo\", img_with_logo)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Mascaras con inRange (Deteccion de colores)\n",
    " ![](https://i.stack.imgur.com/gyuw4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57 238 255]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"people_green_bg.jpg\", cv2.IMREAD_COLOR)\n",
    "img_bg = cv2.imread(\"office_bg.jpg\", cv2.IMREAD_COLOR)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "print(img_hsv[10, 10, :])    # HUE, SATURATION, VALUE\n",
    "\n",
    "lower_bound = np.array([40, 200, 255])\n",
    "upper_bound = np.array([85, 255, 255])\n",
    "mask = cv2.inRange(img_hsv, lower_bound, upper_bound)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "mask_inv = cv2.erode(mask_inv, kernel, iterations=1)\n",
    "\n",
    "img_mask = cv2.bitwise_and(img, img, mask=mask_inv)\n",
    "\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_mask', img_mask)\n",
    "\n",
    "roi = img_bg[-img_mask.shape[0]:,-img_mask.shape[1]:,:]\n",
    "img_bg2 = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "\n",
    "dst = cv2.add(img_mask, img_bg2)\n",
    "cv2.imshow('Final', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "Modifique el kiosko de fotos para que incluya una imagen donde pueda superponer su rostro (como quien mete la cabeza por un agujero en un fondo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHOTO: face_here.jpg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "img = cv2.imread(\"face_here.jpg\")\n",
    "img = cv2.resize(img, (frame.shape[1], frame.shape[0]))\n",
    "roi_img = img[58:195, 270:355]\n",
    "\n",
    "lower_bound = np.array([200, 200, 200])\n",
    "upper_bound = np.array([255, 255, 255])\n",
    "mask = cv2.inRange(roi_img, lower_bound, upper_bound)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    roi_frame = frame[58:195, 270:355]\n",
    "    res1 = cv2.bitwise_and(roi_img, roi_img, mask=mask_inv)\n",
    "    res2 = cv2.bitwise_and(roi_frame, roi_frame, mask=mask)\n",
    "    dst = cv2.add(res1, res2)\n",
    "\n",
    "    img[58:195, 270:355] = dst\n",
    "    \n",
    "    cv2.imshow('WebCam Color', img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"sample5.jpg\")\n",
    "img = cv2.resize(img, (300, 300))\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "\n",
    "img_fil1 = cv2.filter2D(img, -1, kernel)\n",
    "img_fil2 = cv2.blur(img, (5, 5))\n",
    "img_fil3 = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "\n",
    "cv2.imshow('Filter2D', img_fil1)\n",
    "cv2.imshow('Blur', img_fil2)\n",
    "cv2.imshow('Gaussian Filter', img_fil3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"noise_image.jpg\")\n",
    "img = cv2.resize(img, (400, 300))\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "img_fil1 = cv2.medianBlur(img, 5)     #contorno borroso\n",
    "img_fil2 = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "cv2.imshow(\"Median Blur\", img_fil1)\n",
    "cv2.imshow(\"Bilateral Filter\", img_fil2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de bordes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"sample2.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (400, 300))\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "cv2.imshow('edges', edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edges = cv2.Canny(frame, 100, 200)\n",
    "    edges_inv = cv2.bitwise_not(edges)\n",
    "    \n",
    "    cv2.imshow('edges', edges_inv)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Se detectan objetos de color rojo, verde o azul\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "kernel_open = np.ones((30, 30))\n",
    "kernel_close = np.ones((100, 100))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))   # Rango inferior rojo\n",
    "    mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))    # Rango superior rojo\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # erosion + dilation: elimina puntos blancos\n",
    "    mask_open = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)          \n",
    "    # dilation + erosion: elimina agujeros negros\n",
    "    mask_close = cv2.morphologyEx(mask_open, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    mask_final = mask_close\n",
    "    \n",
    "    # Se hallan los contornos de la imagen (blanco sobre fondo negro)\n",
    "    conts, h = cv2.findContours(mask_final, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.drawContours(frame, conts, -1, (255, 0, 0), 3)\n",
    "    \n",
    "    for i in range(len(conts)):\n",
    "        x, y, w, h = cv2.boundingRect(conts[i])\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "           \n",
    "    cv2.imshow(\"WebCam\", frame)\n",
    "    cv2.imshow(\"Mask Final\", mask_final)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar Cascade Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(\"haarcascade_smile.xml\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
    "        \n",
    "        for sx, sy, sw, sh in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 0, 255), 2)\n",
    "       \n",
    "    \n",
    "    cv2.imshow('WebCam', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "Automatice el kiosko de fotos en tkinter para que pueda tomar fotografias de forma automática cuando todas las personas frente a la camara se encuentren mirando a la cámara y sonriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
